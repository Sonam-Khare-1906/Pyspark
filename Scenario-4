source_rdd = spark.sparkContext.parallelize([
    (1, "A"),
    (2, "B"),
    (3, "C"),
    (4, "D")
],1)

target_rdd = spark.sparkContext.parallelize([
    (1, "A"),
    (2, "B"),
    (4, "X"),
    (5, "F")
],2)

# Convert RDDs to DataFrames using toDF()
df1 = source_rdd.toDF(["id", "name"])
df2 = target_rdd.toDF(["id", "name1"])

# Show the DataFrames
df1.show()
df2.show()

unidf=df1.join(df2,["id"],"full")
unidf.show

createcol=unidf.withColumn("comment",expr("""
                                         case when name=name1 then 'match'
                                          else 'mismatch' 
                                          end"""))
createcol.show()

filldf=createcol.filter("comment='mismatch'")
filldf.show()

finaldf=filldf.withColumn("comment",expr("""
                                    case 
                                    when name1 is null then 'New in Source'
                                    when name is null then 'New in Target'
                                    else comment
                                    end
                                   """)).drop("name","name1")
finaldf.show()




+---+----+
| id|name|
+---+----+
|  1|   A|
|  2|   B|
|  3|   C|
|  4|   D|
+---+----+

+---+-----+
| id|name1|
+---+-----+
|  1|    A|
|  2|    B|
|  4|    X|
|  5|    F|
+---+-----+

+---+----+-----+--------+
| id|name|name1| comment|
+---+----+-----+--------+
|  1|   A|    A|   match|
|  2|   B|    B|   match|
|  3|   C| NULL|mismatch|
|  4|   D|    X|mismatch|
|  5|NULL|    F|mismatch|
+---+----+-----+--------+

+---+----+-----+--------+
| id|name|name1| comment|
+---+----+-----+--------+
|  3|   C| NULL|mismatch|
|  4|   D|    X|mismatch|
|  5|NULL|    F|mismatch|
+---+----+-----+--------+

+---+-------------+
| id|      comment|
+---+-------------+
|  3|New in Source|
|  4|     mismatch|
|  5|New in Target|
+---+-------------+
